[2023-01-04 13:38:46.651532] Starting SPDK v22.09-pre git sha1 b3446c862 / DPDK 21.11.0 initialization...
[2023-01-04 13:38:46.651613] [ DPDK EAL parameters: [2023-01-04 13:38:46.651633] bdevio [2023-01-04 13:38:46.651650] --no-shconf [2023-01-04 13:38:46.651666] -c 0x7 [2023-01-04 13:38:46.651681] --huge-unlink [2023-01-04 13:38:46.651695] --log-level=lib.eal:6 [2023-01-04 13:38:46.651711] --log-level=lib.cryptodev:5 [2023-01-04 13:38:46.651727] --log-level=user1:6 [2023-01-04 13:38:46.651743] --base-virtaddr=0x200000000000 [2023-01-04 13:38:46.651760] --match-allocations [2023-01-04 13:38:46.651774] --file-prefix=spdk_pid2297498 [2023-01-04 13:38:46.651787] ]
EAL: No free 2048 kB hugepages reported on node 1
EAL: No available 1048576 kB hugepages reported
TELEMETRY: No legacy callbacks, legacy socket not created
[2023-01-04 13:38:46.814221] app.c: 575:spdk_app_start: *NOTICE*: Total cores available: 3
[2023-01-04 13:38:47.181581] trace_flags.c: 271:trace_register_description: *ERROR*: name (WAL_MOVE_UPDATE_HEAD_END) too long
[2023-01-04 13:38:47.181713] reactor.c: 919:reactor_run: *NOTICE*: Reactor started on core 1
[2023-01-04 13:38:47.188526] reactor.c: 919:reactor_run: *NOTICE*: Reactor started on core 2
[2023-01-04 13:38:47.200511] reactor.c: 919:reactor_run: *NOTICE*: Reactor started on core 0
[2023-01-04 13:38:47.200993] accel_engine.c: 941:sw_accel_engine_init: *NOTICE*: Accel framework software engine initialized.
[2023-01-04 13:38:49.315487] cli.c: 269:cli_start: *NOTICE*: Using empty RDMA connection slot 0
[2023-01-04 13:38:49.444709] rdma_connection.c: 552:rdma_connection_connect: *NOTICE*: connected. posting send...
[2023-01-04 13:38:49.444751] rdma_connection.c: 553:rdma_connection_connect: *NOTICE*: sending local addr (nil) rkey 0 block_cnt 0 block_size 0
[2023-01-04 13:38:49.444777] rdma_connection.c: 609:rdma_connection_connect: *NOTICE*: send req complete
[2023-01-04 13:38:49.464510] rdma_connection.c: 599:rdma_connection_connect: *NOTICE*: received remote addr 0x200295200000 rkey 853493 block_cnt 1310720 block_size 512
[2023-01-04 13:38:49.464535] rdma_connection.c: 617:rdma_connection_connect: *NOTICE*: rdma handshake complete
[2023-01-04 13:38:49.484612] cli.c: 319:cli_start: *NOTICE*: Using empty NVMf connection slot 0
[2023-01-04 13:38:49.484710] cli.c: 130:nvmf_cli_probe_cb: *NOTICE*: Attaching to 10.156.96.128:4420
[2023-01-04 13:38:50.012511] cli.c: 144:nvmf_cli_attach_cb: *NOTICE*: IO queue = 128, IO request = 512
[2023-01-04 13:38:50.012560] cli.c: 164:nvmf_cli_attach_cb: *NOTICE*: Namespace ID: 1 size: 10GB
[2023-01-04 13:38:50.100513] cli.c: 362:cli_start: *NOTICE*: A block in buffer means 1 blocks in ssd
[2023-01-04 13:38:50.100560] cli.c: 269:cli_start: *NOTICE*: Using empty RDMA connection slot 1
[2023-01-04 13:38:50.156729] rdma_connection.c: 552:rdma_connection_connect: *NOTICE*: connected. posting send...
[2023-01-04 13:38:50.156773] rdma_connection.c: 553:rdma_connection_connect: *NOTICE*: sending local addr (nil) rkey 0 block_cnt 0 block_size 0
[2023-01-04 13:38:50.156800] rdma_connection.c: 609:rdma_connection_connect: *NOTICE*: send req complete
[2023-01-04 13:38:50.156821] rdma_connection.c: 599:rdma_connection_connect: *NOTICE*: received remote addr 0x200295200000 rkey 300678 block_cnt 1310720 block_size 512
[2023-01-04 13:38:50.156840] rdma_connection.c: 617:rdma_connection_connect: *NOTICE*: rdma handshake complete
[2023-01-04 13:38:50.196512] cli.c: 319:cli_start: *NOTICE*: Using empty NVMf connection slot 1
[2023-01-04 13:38:50.196558] cli.c: 130:nvmf_cli_probe_cb: *NOTICE*: Attaching to 10.156.96.129:4420
[2023-01-04 13:38:50.252823] cli.c: 144:nvmf_cli_attach_cb: *NOTICE*: IO queue = 128, IO request = 512
[2023-01-04 13:38:50.252876] cli.c: 164:nvmf_cli_attach_cb: *NOTICE*: Namespace ID: 1 size: 10GB
[2023-01-04 13:38:50.284537] cli.c: 362:cli_start: *NOTICE*: A block in buffer means 1 blocks in ssd
[2023-01-04 13:38:50.284581] cli.c: 269:cli_start: *NOTICE*: Using empty RDMA connection slot 2
[2023-01-04 13:38:50.340707] rdma_connection.c: 552:rdma_connection_connect: *NOTICE*: connected. posting send...
[2023-01-04 13:38:50.340760] rdma_connection.c: 553:rdma_connection_connect: *NOTICE*: sending local addr (nil) rkey 0 block_cnt 0 block_size 0
[2023-01-04 13:38:50.340783] rdma_connection.c: 599:rdma_connection_connect: *NOTICE*: received remote addr 0x200295200000 rkey 228974 block_cnt 1310720 block_size 512
[2023-01-04 13:38:50.340801] rdma_connection.c: 609:rdma_connection_connect: *NOTICE*: send req complete
[2023-01-04 13:38:50.340817] rdma_connection.c: 617:rdma_connection_connect: *NOTICE*: rdma handshake complete
[2023-01-04 13:38:50.352599] cli.c: 319:cli_start: *NOTICE*: Using empty NVMf connection slot 2
[2023-01-04 13:38:50.352634] cli.c: 130:nvmf_cli_probe_cb: *NOTICE*: Attaching to 10.156.96.130:4420
[2023-01-04 13:38:50.400828] cli.c: 144:nvmf_cli_attach_cb: *NOTICE*: IO queue = 128, IO request = 512
[2023-01-04 13:38:50.400871] cli.c: 164:nvmf_cli_attach_cb: *NOTICE*: Namespace ID: 1 size: 10GB
[2023-01-04 13:38:50.432543] cli.c: 362:cli_start: *NOTICE*: A block in buffer means 1 blocks in ssd
[2023-01-04 13:38:50.432583] cli.c: 269:cli_start: *NOTICE*: Using empty RDMA connection slot 3
[2023-01-04 13:38:50.492690] rdma_connection.c: 552:rdma_connection_connect: *NOTICE*: connected. posting send...
[2023-01-04 13:38:50.492731] rdma_connection.c: 553:rdma_connection_connect: *NOTICE*: sending local addr (nil) rkey 0 block_cnt 0 block_size 0
[2023-01-04 13:38:50.492758] rdma_connection.c: 609:rdma_connection_connect: *NOTICE*: send req complete
[2023-01-04 13:38:50.492793] rdma_connection.c: 599:rdma_connection_connect: *NOTICE*: received remote addr 0x200295200000 rkey 345654 block_cnt 1310720 block_size 512
[2023-01-04 13:38:50.492813] rdma_connection.c: 617:rdma_connection_connect: *NOTICE*: rdma handshake complete
[2023-01-04 13:38:50.508594] cli.c: 319:cli_start: *NOTICE*: Using empty NVMf connection slot 3
[2023-01-04 13:38:50.508628] cli.c: 130:nvmf_cli_probe_cb: *NOTICE*: Attaching to 10.156.96.131:4420
[2023-01-04 13:38:50.532801] cli.c: 144:nvmf_cli_attach_cb: *NOTICE*: IO queue = 128, IO request = 512
[2023-01-04 13:38:50.532841] cli.c: 164:nvmf_cli_attach_cb: *NOTICE*: Namespace ID: 1 size: 10GB
[2023-01-04 13:38:50.552538] cli.c: 362:cli_start: *NOTICE*: A block in buffer means 1 blocks in ssd
[2023-01-04 13:38:50.552577] bdev_wals.c:1652:wals_bdev_start_all: *NOTICE*: log_blockcnt = 1310720
[2023-01-04 13:38:50.552596] bdev_wals.c:1527:wals_bdev_configure: *NOTICE*: Configure wals bdev Wals1.
[2023-01-04 13:38:50.552656] bdev_wals.c: 193:wals_bdev_create_cb: *NOTICE*: wals_bdev_create_cb, 0x564b3a08ecb0
[2023-01-04 13:38:50.552684] bdev_wals.c: 201:wals_bdev_create_cb: *NOTICE*: Core mask of current thread: 0x1
[2023-01-04 13:38:50.552700] bdev_wals.c: 223:wals_bdev_create_cb: *NOTICE*: register write pollers
[2023-01-04 13:38:50.553457] bdev_wals.c: 193:wals_bdev_create_cb: *NOTICE*: wals_bdev_create_cb, 0x7fc1d4000f60
[2023-01-04 13:38:50.553506] bdev_wals.c: 201:wals_bdev_create_cb: *NOTICE*: Core mask of current thread: 0x4
[2023-01-04 13:38:50.553530] bdev_wals.c: 240:wals_bdev_create_cb: *NOTICE*: register read pollers
[2023-01-04 13:38:50.553603] bdev_wals.c: 299:wals_bdev_destroy_cb: *NOTICE*: wals_bdev_destroy_cb
I/O targets:
  Wals1: 2048000 blocks of 512 bytes (1000 MiB)


     CUnit - A unit testing framework for C - Version 2.1-3
     http://cunit.sourceforge.net/

[2023-01-04 13:38:50.553645] bdev_wals.c: 305:wals_bdev_destroy_cb: *NOTICE*: Ticks from creation: 1977476

Suite: bdevio tests on: Wals1
  Test: blockdev write read block ...passed
  Test: blockdev write zeroes read block ...passed
  Test: blockdev write zeroes read no split ...passed
  Test: blockdev write zeroes read split ...[2023-01-04 13:38:50.580508] cli.c: 814:rdma_cq_poller: *NOTICE*: IO 0x2000072903c0 timeout
[2023-01-04 13:38:50.580817] cli.c: 793:rdma_cq_poller: *NOTICE*: Ignoring io 0x2000072903c0 due to already timeout
passed
  Test: blockdev write zeroes read split partial ...passed
  Test: blockdev reset ...[2023-01-04 13:38:50.607113] bdev_wals.c:1120:wals_bdev_submit_request: *ERROR*: submit request, invalid io type 5
passed
  Test: blockdev write read 8 blocks ...passed
  Test: blockdev write read size > 128k ...passed
  Test: blockdev write read invalid size ...passed
  Test: blockdev write read offset + nbytes == size of blockdev ...passed
  Test: blockdev write read offset + nbytes > size of blockdev ...passed
  Test: blockdev write read max offset ...passed
  Test: blockdev write read 2 blocks on overlapped address offset ...passed
  Test: blockdev writev readv 8 blocks ...passed
  Test: blockdev writev readv 30 x 1block ...passed
  Test: blockdev writev readv block ...passed
  Test: blockdev writev readv size > 128k ...passed
  Test: blockdev writev readv size > 128k in two iovs ...passed
  Test: blockdev comparev and writev ...passed
  Test: blockdev nvme passthru rw ...passed
  Test: blockdev nvme passthru vendor specific ...passed
  Test: blockdev nvme admin passthru ...passed

Run Summary:    Type  Total    Ran Passed Failed Inactive
              suites      1      1    n/a      0        0
               tests     22     22     22      0        0
             asserts     90     90     90      0      n/a

Elapsed time =    0.093 seconds
[2023-01-04 13:38:50.621891] bdev_wals.c: 299:wals_bdev_destroy_cb: *NOTICE*: wals_bdev_destroy_cb
[2023-01-04 13:38:50.621916] bdev_wals.c: 305:wals_bdev_destroy_cb: *NOTICE*: Ticks from creation: 145009168
[2023-01-04 13:38:50.621936] bdev_wals.c: 272:wals_bdev_unregister_read_pollers: *NOTICE*: Unregister read pollers
[2023-01-04 13:38:50.621941] bdev_wals.c: 261:wals_bdev_unregister_write_pollers: *NOTICE*: Unregister write pollers
[2023-01-04 13:38:55.896528] thread.c: 500:thread_exit: *ERROR*: thread app_thread got timeout, and move it to the exited state forcefully
[2023-01-04 13:38:55.896623] thread.c: 350:_free_thread: *WARNING*: timed_poller rdma_cli_connection_poller still registered at thread exit
[2023-01-04 13:38:55.896644] thread.c: 350:_free_thread: *WARNING*: timed_poller nvmf_cli_connection_poller still registered at thread exit
